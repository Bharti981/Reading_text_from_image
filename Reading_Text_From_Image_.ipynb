{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bharti981/Reading_text_from_image/blob/main/Reading_Text_From_Image_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yW79vWxtk3n",
        "outputId": "4a79fa11-a809-4686-a17b-3e5c0c58c0c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.25.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.15.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python pytesseract tensorflow==2.12.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract"
      ],
      "metadata": {
        "id": "sjp2Oy3SvhHG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # This is the correct way to mount your google drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKzP7nQTwrL4",
        "outputId": "28f2379c-b811-429c-fb63-b997872da9de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights  # Download weights\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg  # Download configuration"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzh39anSeh-L",
        "outputId": "c09f84f5-6b64-4d4f-dd05-ec84a6cc408c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-21 18:40:35--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 172.67.185.199, 104.21.88.156, 2606:4700:3037::6815:589c, ...\n",
            "Connecting to pjreddie.com (pjreddie.com)|172.67.185.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘yolov3.weights.1’\n",
            "\n",
            "yolov3.weights.1        [ <=>                ]   8.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-21 18:40:35 (83.0 MB/s) - ‘yolov3.weights.1’ saved [9093]\n",
            "\n",
            "--2025-05-21 18:40:35--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg.1’\n",
            "\n",
            "yolov3.cfg.1        100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-21 18:40:35 (16.5 MB/s) - ‘yolov3.cfg.1’ saved [8342/8342]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def resize_images(image_folder, target_size=(608, 608), max_images=100):\n",
        "    image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
        "    image_files = image_files[:max_images]  # Limit to max_images\n",
        "\n",
        "    for filename in image_files:\n",
        "        if filename.endswith(('.jpg', '.png', '.jpeg')):  # Adjust file extensions as needed\n",
        "            image_path = os.path.join(image_folder, filename)\n",
        "            img = cv2.imread(image_path)\n",
        "            resized_img = cv2.resize(img, target_size)\n",
        "            cv2.imwrite(image_path, resized_img)  # Overwrite original with resized image\n",
        "\n",
        "# Set paths\n",
        "dataset_folder = '/content/drive/MyDrive/Dataset_OCR'  # Path to your Dataset_OCR folder\n",
        "image_folder = dataset_folder  # Assuming images are directly in Dataset_OCR\n",
        "\n",
        "# Resize images\n",
        "resize_images(image_folder)\n",
        "\n",
        "print(f\"Resized {len(os.listdir(image_folder))} images in {image_folder}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Hgzx_3mFb3",
        "outputId": "7c76dd2f-873c-42e9-a439-881ede8674fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Resized 100 images in /content/drive/MyDrive/Dataset_OCR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Task 2.2**\n",
        "\n",
        " **Prepare the Dataset**\n",
        "\n",
        "○ Download and upload the dataset to Google Drive. -  \n",
        "○ Preprocess dataset: resizing images, creating YOLO annotations. -  \n",
        "○ Store preprocessed data in Drive"
      ],
      "metadata": {
        "id": "ZcBVAxLenc0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the gray size resized image in a folder with Name Gray Size in the same drive**"
      ],
      "metadata": {
        "id": "YxZGNhwyXBVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def resize_and_save_gray(image_folder, output_folder, target_size=(608, 608), max_images=100):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
        "    image_files = image_files[:max_images]\n",
        "\n",
        "    for filename in image_files:\n",
        "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
        "            image_path = os.path.join(image_folder, filename)\n",
        "            img = cv2.imread(image_path)\n",
        "\n",
        "            # Convert to grayscale\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Resize the grayscale image\n",
        "            resized_gray_img = cv2.resize(gray_img, target_size)\n",
        "\n",
        "            # Construct the output path\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "            # Save the resized grayscale image\n",
        "            cv2.imwrite(output_path, resized_gray_img)\n",
        "\n",
        "# Example usage\n",
        "dataset_folder = '/content/drive/MyDrive/Dataset_OCR/'\n",
        "output_folder = '/content/drive/MyDrive/Gray_Size' # Output folder\n",
        "\n",
        "resize_and_save_gray(dataset_folder, output_folder)\n",
        "\n",
        "print(f\"Resized grayscale images saved to: {output_folder}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOxT9PJYnb2d",
        "outputId": "8fb30a29-2654-4c22-fdb3-9f64f038e83d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized grayscale images saved to: /content/drive/MyDrive/Gray_Size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Model Training**\n",
        "# ● Task 3.1: Train YOLOv3 Model\n",
        "# ○ Train YOLOv3 model using Colab GPU runtime.\n",
        "# ○ Save trained weights to 'models' folder in Drive.\n",
        "# ○ Validate the model using a subset of data.\n",
        "# ○ Upload validation results (images with bounding boxes) to Drive. **"
      ],
      "metadata": {
        "id": "a3in6iLCbpEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries (if not already installed)\n",
        "!pip install opencv-python pytesseract tensorflow==2.12.0\n",
        "!pip install torch torchvision torchaudio\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "drive_path = '/content/drive/MyDrive/'\n",
        "model_path = os.path.join(drive_path, 'Data Image')\n",
        "dataset_path = os.path.join(drive_path, 'Dataset_OCR')\n",
        "validation_path = os.path.join(drive_path, 'validation_results')\n",
        "\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "os.makedirs(validation_path, exist_ok=True)\n",
        "\n",
        "print(\"Model training complete (placeholder).\")\n",
        "print(\"Trained weights saved to:\", model_path)\n",
        "\n",
        "# Example validation code (replace with your actual validation script)\n",
        "print(\"Model validation complete (placeholder).\")\n",
        "print(\"Validation results saved to:\", validation_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooh-SwqyCzWN",
        "outputId": "2c82aea2-06e2-4a6b-892d-af49587b39da"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.25.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.15.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m23.7/24.6 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m871.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\n",
            "    unknown package:\n",
            "        Expected sha256 a178759ebb095827bd30ef56598ec182b85547f1508941a3d560eb7ea1fbf338\n",
            "             Got        499fba26135a854d01ecd8216f63945bdfe0fc4eb00939bc076907a7c26c55e6\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0mModel training complete (placeholder).\n",
            "Trained weights saved to: /content/drive/MyDrive/Data Image\n",
            "Model validation complete (placeholder).\n",
            "Validation results saved to: /content/drive/MyDrive/validation_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Custom-Object Character Recognition(OCR)\n",
        "# Build a Custom OCR by combining YOLO and Tesseract, to read the specific contents of a Lab\n",
        "# Report and convert it into an editable file. Use  YOLO_V3 to trained on the personal dataset.\n",
        "# Then the coordinates of the detected objects are passed for cropping the detected objects and\n",
        "# storing them in another list. This list is passed through the Tesseract to get the desired output.\n",
        "# Model\n",
        "# ● You can train a custom YOLO_V3 model using your custom dataset.\n",
        "# ● Make a folder named model and put the weights file inside it.\n",
        "# Data\n",
        "# ○ Validate the trained model using a subset of the data.\n",
        "\n",
        "# ○ Upload validation results, including images with bounding boxes, to the colab., the result csv should be three columns and it should extract the test name, Technology, value , units and reference range from each of the image. these fields to be picked from the path of the trained model and not from the csv and once these five fields are extracted from the trained model then a new csv should be generated.\n",
        "\n",
        "# The file is stored as image format in  google drive in Gray_Size folder. it should extraxt features from there. do not do any operations with the csv file, do them from the Gray_Size folder . this has to be done for initial 80 images present in side the Gray_Size folder. Each image to be read and its corresponding text to be extracted and aling with the file name need to be saved . For first 80 images inside Gray_Size folder do this and save them in csv file\n"
      ],
      "metadata": {
        "id": "Cu8Ve-ojdd9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def extract_features_and_save_csv(image_folder, output_csv_path, num_images=80):\n",
        "    results = []\n",
        "    image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))][:num_images]\n",
        "\n",
        "    for filename in image_files:\n",
        "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
        "            image_path = os.path.join(image_folder, filename)\n",
        "            img = cv2.imread(image_path)\n",
        "\n",
        "            # Perform OCR (replace with your actual OCR logic using YOLO and Tesseract)\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            text = pytesseract.image_to_string(gray)\n",
        "\n",
        "            # Placeholder for feature extraction (replace with your actual logic)\n",
        "            test_name = \"Test Name Placeholder\"  # Replace with actual extraction\n",
        "            technology = \"Technology Placeholder\"\n",
        "            value = \"Value Placeholder\"\n",
        "            units = \"Units Placeholder\"\n",
        "            reference_range = \"Reference Range Placeholder\"\n",
        "\n",
        "            results.append({\n",
        "                'filename': filename,\n",
        "                'test_name': test_name,\n",
        "                'technology': technology,\n",
        "                'value': value,\n",
        "                'units': units,\n",
        "                'reference_range': reference_range,\n",
        "                'extracted_text': text # Adding extracted text\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "gray_images_folder = '/content/drive/MyDrive/Gray_Size'\n",
        "output_csv_path = '/content/drive/MyDrive/extracted_features.csv'  # New CSV file name\n",
        "extract_features_and_save_csv(gray_images_folder, output_csv_path)\n",
        "print(f\"Extracted features saved to {output_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plldwjdEQfKL",
        "outputId": "d1c54320-848b-4b1a-9652-5302c1bc5fdc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted features saved to /content/drive/MyDrive/extracted_features.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create bounding boxes around the gray sized images present in Gray_Size folder**"
      ],
      "metadata": {
        "id": "fYMDD5wxtAZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "image_folder='/content/drive/MyDrive/Gray_Size'\n",
        "output_folder='/content/drive/MyDrive/Train_Model/output_folder'\n",
        "\n",
        "def draw_bounding_boxes(image_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
        "            image_path = os.path.join(image_folder, filename)\n",
        "            img = cv2.imread(image_path)\n",
        "\n",
        "            # Convert the image to grayscale\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Perform OCR using pytesseract\n",
        "            data = pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT)\n",
        "\n",
        "            n_boxes = len(data['level'])\n",
        "            for i in range(n_boxes):\n",
        "                if int(data['conf'][i]) > 60:  # Adjust confidence threshold as needed\n",
        "                    (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
        "                    img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, img)\n",
        "\n",
        "# Example usage\n",
        "gray_images_folder = '/content/drive/MyDrive/Gray_Size'\n",
        "output_folder_with_boxes = '/content/drive/MyDrive/Train_Model/Gray_Size_Boxes'\n",
        "\n",
        "draw_bounding_boxes(gray_images_folder, output_folder_with_boxes)\n",
        "\n",
        "print(f\"Bounding boxes drawn and saved to: {output_folder_with_boxes}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhkXXM2Sh27W",
        "outputId": "3b73c86c-c1ff-484f-8970-e29980840204"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Bounding boxes drawn and saved to: /content/drive/MyDrive/Train_Model/Gray_Size_Boxes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create bounding boxes around the gray sized images present in Gray_Size folder with YOLO8**"
      ],
      "metadata": {
        "id": "_7v0tUewu6Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8n model\n",
        "model = YOLO('yolov8n.pt')  # or yolov8n.yaml\n",
        "\n",
        "# Run inference on 'Gray_Size' images\n",
        "results = model.predict(source='/content/drive/MyDrive/Gray_Size', save=True, project='/content/drive/MyDrive/YOLO_Output', name='Gray_Size_Predictions')\n",
        "\n",
        "# Results are saved to /content/drive/MyDrive/YOLO_Output/Gray_Size_Predictions\n",
        "print(\"Bounding boxes created and saved in /content/drive/MyDrive/YOLO_Output/Gray_Size_Predictions\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFIey4wynN41",
        "outputId": "258d4e89-658c-477f-a32f-72491d0c7554"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.141-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.141-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.141 ultralytics-thop-2.0.14\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 76.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_1001.jpg: 640x640 1 laptop, 663.7ms\n",
            "image 2/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_1174.jpg: 640x640 1 clock, 544.4ms\n",
            "image 3/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_122.jpg: 640x640 1 clock, 376.7ms\n",
            "image 4/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_123.jpg: 640x640 1 clock, 385.0ms\n",
            "image 5/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_1248.jpg: 640x640 1 clock, 317.4ms\n",
            "image 6/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_1374.jpg: 640x640 1 refrigerator, 1 book, 228.1ms\n",
            "image 7/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_1433.jpg: 640x640 (no detections), 231.9ms\n",
            "image 8/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_1711.jpg: 640x640 (no detections), 233.9ms\n",
            "image 9/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_1861.jpg: 640x640 1 refrigerator, 1 book, 243.9ms\n",
            "image 10/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_1915.jpg: 640x640 1 laptop, 226.6ms\n",
            "image 11/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_2177.jpg: 640x640 1 clock, 233.5ms\n",
            "image 12/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_2300.jpg: 640x640 1 refrigerator, 230.9ms\n",
            "image 13/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_2505.jpg: 640x640 (no detections), 241.5ms\n",
            "image 14/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_2649.jpg: 640x640 1 book, 229.5ms\n",
            "image 15/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_2691.jpg: 640x640 1 clock, 232.9ms\n",
            "image 16/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_2737.jpg: 640x640 (no detections), 227.5ms\n",
            "image 17/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_2838.jpg: 640x640 (no detections), 245.8ms\n",
            "image 18/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_2841.jpg: 640x640 1 book, 226.2ms\n",
            "image 19/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_2866.jpg: 640x640 (no detections), 260.4ms\n",
            "image 20/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_2885.jpg: 640x640 1 clock, 231.1ms\n",
            "image 21/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_2987.jpg: 640x640 1 laptop, 238.6ms\n",
            "image 22/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_3333.jpg: 640x640 1 clock, 227.6ms\n",
            "image 23/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_3414.jpg: 640x640 (no detections), 225.6ms\n",
            "image 24/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_3439.jpg: 640x640 1 clock, 241.5ms\n",
            "image 25/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_3558.jpg: 640x640 1 book, 238.6ms\n",
            "image 26/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_36.jpg: 640x640 1 laptop, 226.1ms\n",
            "image 27/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_3753.jpg: 640x640 1 laptop, 228.0ms\n",
            "image 28/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_3804.jpg: 640x640 (no detections), 237.9ms\n",
            "image 29/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_3813.jpg: 640x640 1 refrigerator, 1 book, 254.3ms\n",
            "image 30/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_4046.jpg: 640x640 1 laptop, 234.2ms\n",
            "image 31/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_421.jpg: 640x640 1 book, 234.1ms\n",
            "image 32/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_4385.jpg: 640x640 1 clock, 232.5ms\n",
            "image 33/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_4468.jpg: 640x640 1 clock, 251.7ms\n",
            "image 34/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_447.jpg: 640x640 (no detections), 229.6ms\n",
            "image 35/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_4498.jpg: 640x640 1 clock, 229.3ms\n",
            "image 36/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_4523.jpg: 640x640 1 laptop, 227.2ms\n",
            "image 37/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_4557.jpg: 640x640 (no detections), 250.1ms\n",
            "image 38/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_4618.jpg: 640x640 (no detections), 235.4ms\n",
            "image 39/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_4670.jpg: 640x640 1 clock, 243.5ms\n",
            "image 40/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_4683.jpg: 640x640 1 clock, 228.9ms\n",
            "image 41/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_4748.jpg: 640x640 1 laptop, 245.5ms\n",
            "image 42/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_4790.jpg: 640x640 1 book, 233.7ms\n",
            "image 43/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_4979.jpg: 640x640 1 refrigerator, 1 book, 298.2ms\n",
            "image 44/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_5074.jpg: 640x640 (no detections), 387.9ms\n",
            "image 45/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_511.jpg: 640x640 (no detections), 360.1ms\n",
            "image 46/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_517.jpg: 640x640 (no detections), 351.7ms\n",
            "image 47/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_532.jpg: 640x640 1 laptop, 395.0ms\n",
            "image 48/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_5338.jpg: 640x640 (no detections), 360.6ms\n",
            "image 49/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_5357.jpg: 640x640 1 laptop, 364.3ms\n",
            "image 50/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_5503.jpg: 640x640 1 laptop, 361.6ms\n",
            "image 51/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_5608.jpg: 640x640 (no detections), 352.4ms\n",
            "image 52/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_5640.jpg: 640x640 1 book, 409.2ms\n",
            "image 53/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_5816.jpg: 640x640 1 refrigerator, 372.5ms\n",
            "image 54/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_5858.jpg: 640x640 1 refrigerator, 230.2ms\n",
            "image 55/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_5879.jpg: 640x640 1 clock, 229.6ms\n",
            "image 56/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_5896.jpg: 640x640 1 laptop, 231.2ms\n",
            "image 57/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_5928.jpg: 640x640 1 laptop, 223.8ms\n",
            "image 58/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_6185.jpg: 640x640 1 laptop, 225.2ms\n",
            "image 59/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_6214.jpg: 640x640 1 laptop, 242.6ms\n",
            "image 60/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_6222.jpg: 640x640 1 laptop, 231.3ms\n",
            "image 61/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_640.jpg: 640x640 1 clock, 226.5ms\n",
            "image 62/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_657.jpg: 640x640 1 refrigerator, 1 book, 235.0ms\n",
            "image 63/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_6698.jpg: 640x640 1 laptop, 257.1ms\n",
            "image 64/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_6716.jpg: 640x640 1 clock, 226.8ms\n",
            "image 65/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_6723.jpg: 640x640 1 clock, 231.6ms\n",
            "image 66/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_6743.jpg: 640x640 (no detections), 253.4ms\n",
            "image 67/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_6884.jpg: 640x640 (no detections), 248.6ms\n",
            "image 68/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_7075.jpg: 640x640 1 book, 229.1ms\n",
            "image 69/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_7082.jpg: 640x640 (no detections), 230.1ms\n",
            "image 70/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_7083.jpg: 640x640 1 laptop, 244.0ms\n",
            "image 71/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_7109.jpg: 640x640 1 book, 241.8ms\n",
            "image 72/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_7219.jpg: 640x640 1 clock, 232.8ms\n",
            "image 73/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_757.jpg: 640x640 (no detections), 241.6ms\n",
            "image 74/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_7571.jpg: 640x640 (no detections), 244.7ms\n",
            "image 75/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_7601.jpg: 640x640 1 clock, 256.4ms\n",
            "image 76/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_7635.jpg: 640x640 1 book, 232.2ms\n",
            "image 77/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_7758.jpg: 640x640 1 clock, 242.4ms\n",
            "image 78/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_7791.jpg: 640x640 1 book, 242.2ms\n",
            "image 79/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_7805.jpg: 640x640 (no detections), 247.7ms\n",
            "image 80/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_8214.jpg: 640x640 2 clocks, 227.8ms\n",
            "image 81/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_8231.jpg: 640x640 1 laptop, 247.0ms\n",
            "image 82/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_8251.jpg: 640x640 1 book, 229.4ms\n",
            "image 83/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_8265.jpg: 640x640 1 laptop, 247.0ms\n",
            "image 84/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_8302.jpg: 640x640 1 refrigerator, 227.3ms\n",
            "image 85/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_8310.jpg: 640x640 1 laptop, 235.8ms\n",
            "image 86/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_838.jpg: 640x640 1 laptop, 237.9ms\n",
            "image 87/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_8394.jpg: 640x640 2 clocks, 251.4ms\n",
            "image 88/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_8491.jpg: 640x640 1 laptop, 232.8ms\n",
            "image 89/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_8748.jpg: 640x640 (no detections), 232.4ms\n",
            "image 90/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_8749.jpg: 640x640 1 book, 234.8ms\n",
            "image 91/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_9047.jpg: 640x640 1 book, 267.2ms\n",
            "image 92/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_9076.jpg: 640x640 1 clock, 358.7ms\n",
            "image 93/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_9108.jpg: 640x640 1 clock, 347.4ms\n",
            "image 94/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_912.jpg: 640x640 1 clock, 351.8ms\n",
            "image 95/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_9207.jpg: 640x640 1 book, 366.4ms\n",
            "image 96/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_9445.jpg: 640x640 1 laptop, 355.4ms\n",
            "image 97/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_9447.jpg: 640x640 (no detections), 378.8ms\n",
            "image 98/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_9575.jpg: 640x640 (no detections), 361.2ms\n",
            "image 99/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_9691.jpg: 640x640 (no detections), 360.4ms\n",
            "image 100/100 /content/drive/MyDrive/Gray_Size/thyrocare_0_9833.jpg: 640x640 1 clock, 392.2ms\n",
            "Speed: 4.9ms preprocess, 273.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/YOLO_Output/Gray_Size_Predictions\u001b[0m\n",
            "Bounding boxes created and saved in /content/drive/MyDrive/YOLO_Output/Gray_Size_Predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract text from the images with the bounding box and save them in csv file , use the path /content/drive/MyDrive/YOLO_Output/Gray_Size_Predictions**"
      ],
      "metadata": {
        "id": "WwAj3Y5svKQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import pytesseract\n",
        "\n",
        "def extract_text_from_images(yolo_output_folder, csv_output_path):\n",
        "    \"\"\"\n",
        "    Extracts text from images using Tesseract OCR and saves results to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        yolo_output_folder: Path to the folder containing YOLO output images.\n",
        "        csv_output_path: Path to save the output CSV file.\n",
        "    \"\"\"\n",
        "\n",
        "    data = []\n",
        "    for filename in os.listdir(yolo_output_folder):\n",
        "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
        "            image_path = os.path.join(yolo_output_folder, filename)\n",
        "            img = cv2.imread(image_path)\n",
        "\n",
        "            # Preprocess the image (e.g., grayscale conversion, noise reduction)\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Perform OCR using pytesseract\n",
        "            extracted_text = pytesseract.image_to_string(gray)\n",
        "\n",
        "            data.append({'filename': filename, 'extracted_text': extracted_text})\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(csv_output_path, index=False)\n",
        "\n",
        "# Example usage:\n",
        "yolo_output_folder = '/content/drive/MyDrive/YOLO_Output/Gray_Size_Predictions'\n",
        "csv_output_path = '/content/drive/MyDrive/YOLO_Output/extracted_text.csv'\n",
        "extract_text_from_images(yolo_output_folder, csv_output_path)\n",
        "print(f\"Text extracted and saved to {csv_output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxNz897KDCLG",
        "outputId": "68d40139-916c-4923-e4bc-a1a5b622e0d5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text extracted and saved to /content/drive/MyDrive/YOLO_Output/extracted_text.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**use  the path ,  /content/drive/MyDrive/Train_Model/Gray_Size_Boxes to extract text from the gray sized bounding box images and save here in csv file**"
      ],
      "metadata": {
        "id": "lAs_E8dlz_-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def extract_text_from_images(image_folder, csv_output_path):\n",
        "    \"\"\"\n",
        "    Extracts text from images using Tesseract OCR and saves results to a CSV file.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
        "            image_path = os.path.join(image_folder, filename)\n",
        "            img = cv2.imread(image_path)\n",
        "\n",
        "            # Preprocess the image (e.g., grayscale conversion, noise reduction)\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Perform OCR using pytesseract\n",
        "            extracted_text = pytesseract.image_to_string(gray)\n",
        "\n",
        "            data.append({'filename': filename, 'extracted_text': extracted_text})\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(csv_output_path, index=False)\n",
        "\n",
        "# Example usage:\n",
        "image_folder_with_boxes = '/content/drive/MyDrive/Train_Model/Gray_Size_Boxes'\n",
        "csv_output_path = '/content/drive/MyDrive/Train_Model/extracted_text_gray_size_boxes.csv'\n",
        "extract_text_from_images(image_folder_with_boxes, csv_output_path)\n",
        "print(f\"Text extracted from images with bounding boxes and saved to {csv_output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ordZPmogPbLx",
        "outputId": "af69a7ae-4618-462d-c70a-76477f2ba4ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text extracted from images with bounding boxes and saved to /content/drive/MyDrive/Train_Model/extracted_text_gray_size_boxes.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u6t2GaHjPbZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L806_gOtPbjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OURjvSWdPblS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training , Train YOLOv3 model using Colab GPU runtime**"
      ],
      "metadata": {
        "id": "rvxiJ5YvwVp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "    # Load the extracted features from the CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')\n",
        "\n",
        "    # Feature Engineering: Convert text to numerical vectors (Example using word embeddings)\n",
        "vectorizer = TfidfVectorizer(max_features=1000) # Adjust max_features as needed\n",
        "text_features = vectorizer.fit_transform(df['extracted_text']).toarray()\n",
        "\n",
        "    # Reshape the input data for LSTM (samples, timesteps, features)\n",
        "    # Since we are not using sequential data we set timesteps to 1.\n",
        "text_features = text_features.reshape(text_features.shape[0], 1, text_features.shape[1])\n",
        "\n",
        "    # Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(text_features.shape[1], text_features.shape[2]))) # Adjust units as needed\n",
        "model.add(Dense(text_features.shape[2])) # Output layer\n",
        "\n",
        "    # Compile the model\n",
        "model.compile(optimizer='adam', loss='mse') # Use appropriate loss function\n",
        "\n",
        "    # Define a checkpoint to save the best model\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
        "\n",
        "    # Train the model\n",
        "model.fit(text_features, text_features, epochs=10, batch_size=32, validation_split = 0.2, callbacks=[checkpoint])\n",
        "\n",
        "print(\"Training completed. The best model is saved to /content/drive/MyDrive/best_model.h5\")"
      ],
      "metadata": {
        "id": "tjih8HF8nOWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e323a2e5-52dc-4065-9692-f0420dc2c06f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 405ms/step - loss: 0.0010 - val_loss: 5.5842e-04\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 9.7619e-04 - val_loss: 5.5293e-04\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 9.5376e-04 - val_loss: 5.5097e-04\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 9.3456e-04 - val_loss: 5.5088e-04\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 9.1951e-04 - val_loss: 5.5212e-04\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 9.0578e-04 - val_loss: 5.5412e-04\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 8.9441e-04 - val_loss: 5.5634e-04\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 8.8370e-04 - val_loss: 5.5843e-04\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 8.7473e-04 - val_loss: 5.6079e-04\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 8.6643e-04 - val_loss: 5.6328e-04\n",
            "Training completed. The best model is saved to /content/drive/MyDrive/best_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# === Load the dataset ===\n",
        "df = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')  # <-- Adjust path if needed\n",
        "texts = df['extracted_text'].fillna('')\n",
        "\n",
        "# === TF-IDF Vectorization ===\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "text_features = vectorizer.fit_transform(texts).toarray()\n",
        "\n",
        "# === Reshape for LSTM input: (samples, timesteps=1, features) ===\n",
        "text_features = text_features.reshape(text_features.shape[0], 1, text_features.shape[1])\n",
        "\n",
        "# === Define the LSTM Autoencoder Model ===\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1, text_features.shape[2])))  # Use Input() layer (avoid old input_shape keyword)\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(text_features.shape[2]))  # Output same size as input for reconstruction\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# === Define save paths ===\n",
        "model_h5_path = r'/content/drive/MyDrive/Project-10/best_model.h5'\n",
        "model_saved_path = r'/content/drive/MyDrive/Project-10/best_model_saved'\n",
        "vectorizer_path = r'/content/drive/MyDrive/Project-10/tfidf_vectorizer.pkl'\n",
        "\n",
        "# === Define checkpoint for .h5 ===\n",
        "checkpoint = ModelCheckpoint(model_h5_path, monitor='val_loss', save_best_only=True, mode='min')\n",
        "\n",
        "# === Train the model ===\n",
        "model.fit(\n",
        "    text_features,\n",
        "    text_features,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "# === Save model also as TensorFlow SavedModel format ===\n",
        "model.save(model_saved_path)\n",
        "\n",
        "# === Save TF-IDF vectorizer ===\n",
        "with open(vectorizer_path, 'wb') as f:\n",
        "    pickle.dump(vectorizer, f)\n",
        "\n",
        "print(\"Training completed.\")\n",
        "print(f\" Best model saved to: {model_h5_path}\")\n",
        "print(f\" SavedModel format also saved to: {model_saved_path}\")\n",
        "print(f\"Vectorizer saved to: {vectorizer_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRHLy2RFrtKM",
        "outputId": "83aa58e0-f057-422b-9780-771d1e878aa3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 327ms/step - loss: 0.0010 - val_loss: 5.5508e-04\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 9.7449e-04 - val_loss: 5.5067e-04\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 9.5317e-04 - val_loss: 5.4922e-04\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 9.3459e-04 - val_loss: 5.4965e-04\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 9.1934e-04 - val_loss: 5.5114e-04\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 9.0605e-04 - val_loss: 5.5322e-04\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 8.9487e-04 - val_loss: 5.5574e-04\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 8.8471e-04 - val_loss: 5.5830e-04\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 8.7572e-04 - val_loss: 5.6050e-04\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 8.6764e-04 - val_loss: 5.6304e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed.\n",
            " Best model saved to: /content/drive/MyDrive/Project-10/best_model.h5\n",
            " SavedModel format also saved to: /content/drive/MyDrive/Project-10/best_model_saved\n",
            "Vectorizer saved to: /content/drive/MyDrive/Project-10/tfidf_vectorizer.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validating the Model - Error Check**"
      ],
      "metadata": {
        "id": "lJwxdY671G0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the best model\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/best_model.h5')\n",
        "\n",
        "# Load the extracted features from the CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')\n",
        "\n",
        "# Feature Engineering: Convert text to numerical vectors (Example using word embeddings)\n",
        "vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
        "text_features = vectorizer.fit_transform(df['extracted_text']).toarray()\n",
        "\n",
        "# Reshape the input data for LSTM\n",
        "text_features = text_features.reshape(text_features.shape[0], 1, text_features.shape[1])\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(text_features)\n",
        "\n",
        "# Assuming y_true is the same as text_features for autoencoder-like setup\n",
        "y_true = text_features.reshape(text_features.shape[0],text_features.shape[2]) # Reshape to match prediction shape\n",
        "\n",
        "# Calculate accuracy\n",
        "# Accuracy is not the best metric for regression or autoencoder-like tasks.\n",
        "# Consider using Mean Squared Error (MSE) or other relevant metrics.\n",
        "# Convert predictions to class labels if needed.\n",
        "\n",
        "# Example using MSE (Mean Squared Error):\n",
        "mse = np.mean(np.square(y_true - y_pred))\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Example using accuracy (not the best metric for this setup):\n",
        "# Find the indices of the maximum value\n",
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "y_true_class = np.argmax(y_true, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_true_class, y_pred_class)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4EUaJ_G_dwv",
        "outputId": "a9e3f549-7a27-424b-9ebb-25969e984032"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n",
            "Mean Squared Error: 0.0008483445055137186\n",
            "Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the extracted features from the CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')\n",
        "\n",
        "# Check the data types of all columns\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZlwy2CkEVGa",
        "outputId": "acbfbbfd-ce2a-47dc-9a96-c5adc7ba613c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename           object\n",
            "test_name          object\n",
            "technology         object\n",
            "value              object\n",
            "units              object\n",
            "reference_range    object\n",
            "extracted_text     object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# 1. Load and Preprocess Data\n",
        "df = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')\n",
        "\n",
        "# 2. Feature Engineering with TF-IDF (before one-hot encoding)\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "text_features = vectorizer.fit_transform(df['extracted_text']).toarray()\n",
        "text_features = text_features.reshape(text_features.shape[0], 1, text_features.shape[1])\n",
        "\n",
        "# Convert numerical columns to numeric data types\n",
        "numerical_cols = ['value', 'reference_range']\n",
        "for col in numerical_cols:\n",
        "    try:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    except ValueError:\n",
        "        print(f\"WARNING: Could not convert column '{col}' to numeric.\")\n",
        "\n",
        "# Handle missing values (if any) - choose one method\n",
        "# df.dropna(subset=numerical_cols, inplace=True)  # Remove rows with NaN\n",
        "# df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())  # Impute with mean\n",
        "\n",
        "# One-hot encode string columns (excluding 'extracted_text')\n",
        "string_columns_to_encode = [col for col in df.select_dtypes(include=['object']).columns if col != 'extracted_text']\n",
        "for col in string_columns_to_encode:\n",
        "    df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
        "    df.drop([col], axis=1, inplace=True)\n",
        "\n",
        "# 3. Split Data (including text_features)\n",
        "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(\n",
        "    text_features, text_features, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# One-hot encoded data (if needed)\n",
        "X_train_ohe, X_test_ohe, y_train_ohe, y_test_ohe = train_test_split(\n",
        "    df, df, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 4. Build and Train LSTM Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(X_train_text.shape[1], X_train_text.shape[2])))\n",
        "model.add(Dense(X_train_text.shape[2]))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/drive/MyDrive/best_model.h5', monitor='val_loss', save_best_only=True, mode='min'\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train_text,\n",
        "    y_train_text,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_text, y_test_text),\n",
        "    callbacks=[checkpoint],\n",
        ")\n",
        "\n",
        "print(\"Training completed. The best model is saved to /content/drive/MyDrive/best_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we-G4XY3E9Ps",
        "outputId": "1ad57d28-1294-4e78-a0c5-023533c6210d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 521ms/step - loss: 8.8965e-04 - val_loss: 9.8266e-04\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 8.6883e-04 - val_loss: 9.6398e-04\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 8.5097e-04 - val_loss: 9.4844e-04\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 8.3631e-04 - val_loss: 9.3539e-04\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 8.2471e-04 - val_loss: 9.2417e-04\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 8.1502e-04 - val_loss: 9.1410e-04\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 8.0660e-04 - val_loss: 9.0494e-04\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 7.9900e-04 - val_loss: 8.9656e-04\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 7.9228e-04 - val_loss: 8.8899e-04\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 7.8672e-04 - val_loss: 8.8204e-04\n",
            "Training completed. The best model is saved to /content/drive/MyDrive/best_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Error and the accuracy of the above model**"
      ],
      "metadata": {
        "id": "aHGGkAfr1x7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model = load_model('/content/drive/MyDrive/best_model.h5')\n",
        "\n",
        "# Load the preprocessed data (including one-hot encoded features)\n",
        "df = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')\n",
        "\n",
        "# 2. Feature Engineering with TF-IDF (before one-hot encoding)\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "text_features = vectorizer.fit_transform(df['extracted_text']).toarray()\n",
        "text_features = text_features.reshape(text_features.shape[0], 1, text_features.shape[1])\n",
        "\n",
        "# Convert numerical columns to numeric data types\n",
        "numerical_cols = ['value', 'reference_range']\n",
        "for col in numerical_cols:\n",
        "    try:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    except ValueError:\n",
        "        print(f\"WARNING: Could not convert column '{col}' to numeric.\")\n",
        "\n",
        "# Handle missing values (if any) - choose one method\n",
        "# df.dropna(subset=numerical_cols, inplace=True)  # Remove rows with NaN\n",
        "# df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())  # Impute with mean\n",
        "\n",
        "# One-hot encode string columns (excluding 'extracted_text')\n",
        "string_columns_to_encode = [col for col in df.select_dtypes(include=['object']).columns if col != 'extracted_text']\n",
        "for col in string_columns_to_encode:\n",
        "    df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
        "    df.drop([col], axis=1, inplace=True)\n",
        "\n",
        "# 3. Split Data (including text_features)\n",
        "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(\n",
        "    text_features, text_features, test_size=0.2, random_state=42\n",
        ")\n",
        "# ... (rest of your data loading and preprocessing code)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_text)\n",
        "\n",
        "# Calculate accuracy (adjust as needed)\n",
        "mse = np.mean(np.square(y_test_text.reshape(y_test_text.shape[0],y_test_text.shape[2]) - y_pred))\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# You can also try to calculate an accuracy like this:\n",
        "# Accuracy is not the best metric for regression or autoencoder-like tasks.\n",
        "# Consider using Mean Squared Error (MSE) or other relevant metrics.\n",
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "y_true_class = np.argmax(y_test_text.reshape(y_test_text.shape[0], y_test_text.shape[2]), axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_true_class, y_pred_class)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q7yfSjKFsAs",
        "outputId": "972b1caf-53aa-4568-db6e-30da0fe403bf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 179ms/step\n",
            "Mean Squared Error: 0.0008807250245012139\n",
            "Accuracy: 0.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the model in pickle file**"
      ],
      "metadata": {
        "id": "LAvxaBjY0hqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming 'model' is your trained LSTM model\n",
        "# Save the model to a pickle file\n",
        "with open('/content/drive/MyDrive/trained_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "print(\"Model saved to /content/drive/MyDrive/trained_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia1AIi-eGx0b",
        "outputId": "e4dab64c-72f8-4368-add1-069dc8e365b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/trained_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DKCqv5w1GyEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hyper  tune the model to improve accuracy of the model**"
      ],
      "metadata": {
        "id": "AWh2BcL5EURs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -q -U keras-tuner\n",
        "import kerastuner as kt\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Feature Engineering with TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "text_features = vectorizer.fit_transform(texts).toarray()\n",
        "\n",
        "# Reshape for LSTM input: (samples, timesteps=1, features)\n",
        "text_features = text_features.reshape(text_features.shape[0], 1, text_features.shape[1])\n",
        "\n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    text_features, text_features, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=128, step=32),\n",
        "                   activation='relu',\n",
        "                   input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(X_train.shape[2]))  # Output layer\n",
        "\n",
        "    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop']),\n",
        "                  loss='mse',  # Use appropriate loss function\n",
        "                  metrics=['mse']) # Add mse as metric for monitoring\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',  # or 'val_mse' if you use val_mse as metric\n",
        "    max_trials=5,  # Number of hyperparameter combinations to try\n",
        "    executions_per_trial=3,  # Number of times to run each trial\n",
        "    directory='my_dir',\n",
        "    project_name='helloworld'\n",
        ")\n",
        "\n",
        "# Perform hyperparameter search\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"Best hyperparameters: {best_hps.values}\")\n",
        "\n",
        "# Build and train the best model\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "best_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "\n",
        "# Evaluate the best model\n",
        "loss, mse = best_model.evaluate(X_test, y_test)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"MSE:\", mse)\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('/content/drive/MyDrive/best_tuned_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZAEDl1JCOiN",
        "outputId": "eae492cf-e131-4a51-9bcf-68a194a638b5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 09s]\n",
            "val_loss: 0.0008814388808483878\n",
            "\n",
            "Best val_loss So Far: 0.0008814388808483878\n",
            "Total elapsed time: 00h 00m 59s\n",
            "Best hyperparameters: {'units': 64, 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 513ms/step - loss: 8.9067e-04 - mse: 8.9067e-04 - val_loss: 9.8365e-04 - val_mse: 9.8365e-04\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 8.6925e-04 - mse: 8.6925e-04 - val_loss: 9.6464e-04 - val_mse: 9.6464e-04\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 8.5078e-04 - mse: 8.5078e-04 - val_loss: 9.4872e-04 - val_mse: 9.4872e-04\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 8.3637e-04 - mse: 8.3637e-04 - val_loss: 9.3515e-04 - val_mse: 9.3515e-04\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 8.2432e-04 - mse: 8.2432e-04 - val_loss: 9.2349e-04 - val_mse: 9.2349e-04\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 8.1446e-04 - mse: 8.1446e-04 - val_loss: 9.1307e-04 - val_mse: 9.1307e-04\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 8.0583e-04 - mse: 8.0583e-04 - val_loss: 9.0377e-04 - val_mse: 9.0377e-04\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 7.9808e-04 - mse: 7.9808e-04 - val_loss: 8.9538e-04 - val_mse: 8.9538e-04\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 7.9168e-04 - mse: 7.9168e-04 - val_loss: 8.8770e-04 - val_mse: 8.8770e-04\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 7.8548e-04 - mse: 7.8548e-04 - val_loss: 8.8090e-04 - val_mse: 8.8090e-04\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 8.8090e-04 - mse: 8.8090e-04\n",
            "Loss: 0.0008808980346657336\n",
            "MSE: 0.0008808980346657336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtW34rV6QT3I",
        "outputId": "3198ce24-cbfc-46b5-8de6-2cd487192bdb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1POaJyNLnOdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Custom OCR by combining YOLO and Tesseract, to read the specific contents of a Lab\n",
        "\n",
        "Report and convert it into an editable file. Use  YOLO_V3 to trained on the personal dataset.\n",
        "\n",
        "Then the coordinates of the detected objects are passed for cropping the detected objects and\n",
        "\n",
        "storing them in another list. This list is passed through the Tesseract to get the desired output.\n",
        "\n",
        "**Model**\n",
        "\n",
        "● You can train a custom YOLO_V3 model using your custom dataset.\n",
        "\n",
        "● Make a folder named model and put the weights file inside it."
      ],
      "metadata": {
        "id": "wN40wmVYhlJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f0xzJmZvwoTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PTv7klgIvhPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_21Xd5suvhTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BxhozWo9vhXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wIHDR_-_vhbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sIsc5q8lvhdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YTA_AtoDvhgG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}